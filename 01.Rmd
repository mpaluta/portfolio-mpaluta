# Hello, would you like to buy one of our utilitarian cars or one of our egoistic ones? {#ethical cars}

#### Keywords {-}

(filler - not sure what goes here)

## A moment of decision

The car in front of you slams on its brakes. You feel the rush of adrenaline and your limbic system takes over. There's no time to stop. You swerve and collide with a car next to you. That driver and her three children in the backseat suffer traumatic injuries. You walk away unharmed.

Rewind.

The car in front of you slams on its brakes. You feel the rush of adrenaline and your limbic system takes over.  This time, your autonomous car makes the decision for you. With an instant calculation it slams on the brakes. You hit the car in front of you and airbags deploy. You suffer from a broken nose and the driver in front of you is unharmed. The woman pulls over safely with her three children and calls you an ambulance.

What did the second car have that the first didn't? Troves of information, yes, and a lightning-quick algorithm. But it had something else too. It had knowledge of the other drivers around you and the impact of your decision on them. You were only aware of yourself and your own well-being (and how could you not be, driving a metal coffin at 60 miles per hour). But your car quickly calculated the expected utility of all those around you, weighted those utilities in accordance with its priorities, and chose the optimal solution.

Well, this sounds fancy, but how does your car know how to weight your own well-being against that of another driver? In fact, as a consumer, why would you buy a car from manufacturer A that values you equivalently to those around me when you could buy a car from manufacturer B that values you at double the importance of those around you? Do you follow this to its end and buy the car that values you above all else? How do you feel when the situation is swapped, and another driver's car chooses to sacrifice you because you are less important than its passenger?

## How do we build an ethical framework?

This reveals an interesting misunderstanding about artificial intelligence: the mathematics are actually the easy part. It's the policy and human value alignment that is difficult.

<!-- ...or include images directly from the web. Cite your sources! -->
```{r machine-learning,echo=FALSE,fig.cap='[xkcd: Machine Learning](https://xkcd.com/1838/)',fig.align='center',out.width='50%'}
knitr::include_graphics('https://imgs.xkcd.com/comics/machine_learning.png')
```

## The future state.

Society is going to have to become increasingly more comfortable making difficult ethical decisions as we have to explicitly program them into our systems.
