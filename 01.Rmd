# Hello, would you like to buy one of our utilitarian cars or one of our egoistic ones? {#ethical-cars}

#### Keywords {-}

autonomous, self-driving, vehicles, cars, ethics

## A moment of decision

The car in front of you slams on its brakes. You feel a rush of adrenaline. There's no time to stop. You swerve and collide with a car next to you. That driver and her two children in the backseat suffer traumatic injuries. You walk away unharmed.

Rewind.

The car in front of you slams on its brakes. You feel a rush of adrenaline.  This time, your autonomous car makes a decision for you. With an instant calculation it slams on the brakes. You hit the car in front of you and airbags deploy. You suffer from a few bruises and the driver in front of you is unharmed. The woman pulls over safely with her two children and calls you an ambulance.

What did the second car have that the first didn't? Troves of information, yes, and a lightning-quick algorithm, but it had something else too. It had knowledge of the other drivers around you and the impact of your decision on them. Your fight or flight response focused on your own well-being, but your car quickly calculated the expected utility of all those around you, weighted those utilities in accordance with its preferences, and chose the optimal solution.

## Democratize ethics

Well, that outcome sounds fancy, but how does your car know how to weight your own well-being against that of another driver? In fact, as a consumer, why would you buy a car from manufacturer A that values you equivalently to those around me when you could buy a car from manufacturer B that values you at five times the importance of those around you? Do you follow this to its end and buy the car that values you unequivocally? How would you feel if the tables were turned and another driver's car chooses to sacrifice you without hesitation?

This is a classic market failure - the tragedy of the commons. Everyone's self-interest inevitably depletes the common good. The solution to a market failure, of course, is policy. This does *not*, however, necessitate that we weight all persons equally. We could choose that model, but it's just one of many possible models. Most people don't want to drive cars that would just as soon kill the driver as anyone else, but most people also don't want cars on the road that only value the driver. We need a compromise.

But here we run into a problem: the average person doesn't want to spend much time thinking about how autonomous agents should behave, and worse yet, they would rather not make a decision at all than make a hard decision. They don't realize that indecision is the worst possible decision; it lets any nefarious car manufacturer do whatever he wants to do to achieve maximum sales. So the problem is: how do we make it palatable for the average citizen to engage in developing a policy that reflects societal values?

I propose that we follow the example of our philosopher friends and pose thought experiments. These bite-sized problems break complex situations into structured, digestible pieces. Our policymakers (at any level of government) can survey their constituents, asking how they wish an autonomous vehicle to act in a variety of fictitious situations. For example, if the car has to choose between running over a baby or an adult, all else equal, what choice should it make? Any citizen who does not wish to answer need not, but by democratizing the process, we give everyone the opportunity to affect the society they will live in. The policymakers, in coordination with a data science team, can derive an empirical model to best fit respondents' wishes and legally mandate that all vehicle programmers follow that system of ethics.

## By the people, for the people

Society is going to have to become increasingly comfortable making difficult ethical decisions as we have to explicitly program them into our systems. There are autonomous agents making decisions right now that affect the well-being of humankind. Our reluctance to answer difficult philosophical questions means we are leaving the decision to corporations who are not necessarily aligned with the average citizen's best interests. By democratizing ethical policy, we empower the population to author their own future and simultaneously develop systems that elevate the greater good of society.

Testing Bibliography. [@noauthor_moral_nodate]
