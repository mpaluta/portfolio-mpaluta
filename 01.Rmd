# Ethical Cars: A Case Study of Democratizing Ethics {#democratize-ethics}

#### Keywords {-}

democracy, ethics, policy, data ethics, autonomous, self-driving, vehicles, cars

## Hello, would you like to buy one of our utilitarian cars or one of our egotistical cars?

The car in front of you slams on its brakes. You feel a rush of adrenaline. There's no time to stop. You swerve and collide with a car next to you. That driver and her two children in the backseat suffer traumatic injuries. You walk away unharmed.

Rewind.

The car in front of you slams on its brakes. You feel a rush of adrenaline.  This time, your autonomous car makes a decision for you. With an instant calculation it slams on the brakes. You hit the car in front of you and airbags deploy. You suffer from a few bruises and the driver in front of you is unharmed. The woman pulls over safely with her two children and calls you an ambulance.

What did the second car have that the first didn't? It had troves of information and lightning-quick decisions, but more importantly, it evaluated the impact of its decision on all other agents in the situation. It weighted probabilities and utilities with its preferential algorithm and chose the optimal solution.

Okay, but how does a car know how to weight your own well-being against that of another driver? In fact, as a consumer, why would you buy a car from manufacturer A that values you equivalently to those around you when you could buy a car from manufacturer B that values you five times more than those around you? Do you follow this logic to its end and buy the car that values you unequivocally? How would you feel if the tables were turned and another driver's car chooses to sacrifice you without hesitation?

This problem is not unique to cars. While they are the most salient example of this tradeoff in popular culture, financial algorithms, healthcare decisions, & persuasive social media pose just as much threat to ethical norms, if not more. If centuries of philosophers can't even agree on a system of ethics, how are we the people supposed to explicitly program it into our society?

## A social approach

The answer lies in the question: we the people should decide. Not corporations and not special interests, but a democratized solution. Ethics, insofar as we can tell, are defined by topical social opinion, so the best way to map ethics onto algorithms is by actually *asking society*. To examine this thesis, we will continue to use the easy to understand example of autonomous vehicles.

Unfortunately, the average person doesn't want to spend much time thinking about how autonomous agents should behave, so we need techniques to make it palatable for the average citizen to engage in developing data policy. A good start is to follow the example of our philosopher friends and pose thought experiments. These bite-sized problems, like the one above, break complex situations into structured, digestible pieces (that are actually quite fun to think about). This is being attempted already, and sites such as Moral Machine by MIT Media Lab allow a user to browse through thought experiments and select their desired outcomes [@noauthor_moral_nodate]. The user is then given a report out on their preferences, such as saving more lives, obeying laws, or avoiding intervention.

This is a great start, but some aspects could be improved. One glaring omission is the lack of the self in any of these cases. Oneself is the character who most complicates ethical thinking. I would argue that personalizing the situations with the self is essential in order to draw out our most innately human aversions to truly evaluate what sort of policy we can stomach. Simulations and animations can also be utilized - anything to make the example feel more personal and less academic.

An additional improvement point is outreach. Our system requires widespread adoption and should represent its stakeholders. This could be interpreted two ways. First, it could be taken to just be car purchasers or users. We could mandate such a survey prior to purchase, rental, or rideshare of a car in order to build a dynamic dataset of user opinion. Second, it could involve the broader public, since even if not users themselves, they may be other drivers or pedestrians involved in autonomous vehicle decisions. This outreach is harder but more appropriate. It is probably best accomplished through polling at a local governmental level (think akin to initiative on the ballot). A city could choose its own system of ethics reflective of its local culture, and autonomous vehicles must behave within that system of ethics while operating within city boundaries.

Another important aspect to address is how the empirical data gets mapped to a policy. Moral Machine has the right idea here, abstracting a subset of relevant features from the state space which can be stored in a public database. This up-to-date data set can then be reverse-fed into the vehicle's machine learning algorithm to weight each parameter and allow it to make split-second decisions. It is probably best for the weights not to be made public as they may influence users to dishonestly "over-vote" in one direction if the status quo isn't to their liking. Due to differences in company's algorithms, a one-to-one mapping of weights is probably impossible, but they could for example be given the middle 20% range of votes, and between those boundary conditions they can use any algorithm they want to try to maintain a proprietary competitive advantage. A regulatory agency can audit corporations' algorithms regularly to determine compliance.

This is not to say that democracy is without its flaws. First, the weighting algorithm would be influenced by current events. If a car crashes due to behavior at one end of the spectrum, voting will immediately push it the other way. However, I would argue that this is desirable behavior as it maps current social ethics onto policy. It applies an immediate fix to calm the public, and over time there will be reversion to the mean as hysteria fades.

Second, democracy is subject to populism and tyranny of the majority. This effect can be partially mitigated by using median or mean responses to determine criteria, rather than simply going with the plurality. This system would model more of a parliamentary government than a first-past-the-post government.

Third, these issues will inevitably become politicized. Partisanship touches everything in modern culture. There isn't much of a way around this, but direct democracy at least ensures that views won't be misrepresented.

Finally, there need to be sufficient regulations in place to ensure that companies are not buying users' votes through any sort of incentive structure such as discounts or free rides for a preferred vote. This system would need to be treated with the sanctity of our current voting system in order to remain effective.

## By the people, for the people

Despite these potential drawbacks, this idea would not only grant a pragmatic solution, but also a philosophical triumph for society. It would represent a willingness to have conversation and compromise in a previously unquantifiable area. It would mean that we truly author our future in an AI-dominated society and have no one to blame if we misguide the laws ourselves.

Society is going to have to become increasingly comfortable making difficult ethical decisions as we have to explicitly program them into our systems. There are autonomous agents making decisions right now that affect the well-being of humankind. Our reluctance to answer difficult philosophical questions means we are leaving the decision to corporations who are not necessarily aligned with the average citizen's best interests. By democratizing ethical policy, we empower the population to author their own future and simultaneously develop systems that elevate the greater good of society.
